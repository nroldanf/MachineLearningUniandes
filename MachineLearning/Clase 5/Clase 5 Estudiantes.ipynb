{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 5: Aprendizaje no supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia del aprendizaje supervisado, en el *análisis no supervisado* los datos no tienen etiqueta, y solo contamos con sus características $x_i$. \n",
    "Todos lucen igual y el objetivo es encontrar estructuras subyacentes en los datos: patrones, grupos, redundancias...:\n",
    "\n",
    "<center>\n",
    "<img src='im/NoSupervisado.PNG'> \n",
    "<img src='im/NoSupervisadoClas.PNG'>\n",
    "</center>\n",
    "\n",
    "Intentaremos dar respuesta a las siguientes preguntas:\n",
    "- ¿Hay alguna manera informativa de visualizar los datos?\n",
    "- ¿Existen subgrupos interesantes dentro de la muestra observada?\n",
    "- ¿Hay datos atípicos o anomalías?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué tipos de datos es cada una de las variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Avg. Session Length', 'Time on App', 'Time on Website', 'Yearly Amount Spent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción de dimensionalidad: Análisis de Componentes Principales (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Queremos resumir la información según las direcciones de las características en las que más varían las observaciones.\n",
    "\n",
    "- Un _Componente Principal_ $Z$ es una combinación lineal de las características de la muestra:\n",
    "\n",
    "$$Z = \\varphi_1 X_1 + \\varphi_2 X_2 + ... + \\varphi_k X_k.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener el _j_-ésimo componente principal $Z_j$ se procede de la siguiente manera manera:\n",
    "\n",
    "$$Z_j = \\varphi_{1,j} X_1 + \\varphi_{2,j} X_2 + ... + \\varphi_{k,j} X_k$$\n",
    "\n",
    "$$\\max_{\\vec \\varphi_j} \\left\\{ Var(Z_j) \\right\\} = \\max_{\\vec \\varphi_j} \\left\\{ \\frac{1}{N}\\sum_{i=1}^{N}(\\varphi_{1,j} x_{i,1} + \\varphi_{2,j} x_{i,2} + ... + \\varphi_{k,j} x_{k,N})^2 \\right\\},$$\n",
    "\n",
    "con las restricciones \n",
    "$$\\sum_{i=1}^{k}\\varphi_{i,j}^2 = 1, ~~~~~ \\vec\\varphi_j \\perp Z_1, ~\\vec\\varphi_j \\perp Z_2, ..., ~\\vec\\varphi_j \\perp Z_{j-1}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = ecommerce_data.loc[:, columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los componentes principales maximizan la varianza observada de los datos y, además, generan el hiperplano más cercano a las observaciones\n",
    "\n",
    "<center>\n",
    "<img src='im/PCAajuste.PNG'> \n",
    "</center>\n",
    "\n",
    "Esto motiva a usarlos tambien como variables predictoras en modelos de aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuántos componentes usamos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos un codo en la gráfica: cuando la ganancia en varianza explicada no compense el usar un componente adicional (más dimensionalidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué ocurre si no normalizamos las variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia en la escala genera que la variable de _gasto_ recoja el 99 % de la varianza y por tanto sea el primer componente principal exclusivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Existen otros algoritmos de reducción de dimensionalidad:\n",
    "\n",
    "- MCA.\n",
    "- tSNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de clustering: $k$-medias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos divdir la base de datos en diferentes grupos tales que las observaciones en un mismo grupo sean _similares_ entre sí, y observaciones en grupos distintos sean _diferentes_ entre ellas.\n",
    "\n",
    "**¿Cómo definimos dos datos como similares o diferentes?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El método de agrupamiento de $k$-medias busca dividir el conjunto de datos en $k$ grupos diferentes que no se sobrelapan.\n",
    "- Cada una de las observaciones $x_i$ pertenece a uno, y solo uno, de los clusters $C_k$.\n",
    "- Para cada grupo, se calcula su varianza interna (_within cluster variation_):\n",
    "\n",
    "$$Var(C_k) = \\sum_{j=1}^n Var(X_j^k) = \\sum_{j=1}^n\\left(\\sum_{x_i\\in C_k}(x_{i,j}-\\bar X_j^k)^2\\right).$$\n",
    "\n",
    "- Queremos que la sumas de esta varianzas de los grupos sea lo más pequeña posible, en otras palabras, que los datos dentro de cada cluster sean lo más parecidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los centroides de cada grupo nos permiten entender qué tipo de observaciones hay un cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuántos grupos se deben escoger?\n",
    "\n",
    "- Información propia del problema.\n",
    "- Nuevamente usamos la regla del codo: cuando la ganancia en menor varianza de los grupos no compense tener un grupo adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existen muchos otros algoritmos de agrupamiento:\n",
    "\n",
    "- $k$-prototipos.\n",
    "- Clústering jerárquico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de anomalías: Mixturas gaussianas\n",
    "\n",
    "La idea es construir un _Modelo_ que permita estimar $p(x)$: la probabilidad de observar las características de cada uno de los datos. \n",
    "\n",
    "Con este modelo, si la probabilidad de observar $x_{test}$ es menor que cierto umbral de _rareza_: $p(x_{test}) < \\varepsilon$, se cataloga $x_{test}$ como una observación _anómala_. Por el contrario, si $p(x_{test}) \\geq \\varepsilon$, $x_{test}$ supera el umbral de _rareza_ y se cataloga como una observación normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Modelo de $p(x)$ debería indicar que observaciónes en el centro ocurren con mucha frecuencia,observaciones más alejadas ocurrirán frecuentemente, observaciones aún más alejadas ocurriren con relativa frecuencia, pero observaciones muy alejadas ocurrirán rara vez:\n",
    "\n",
    "<center>\n",
    "<img src='im/model_anom.PNG'> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma natural es suponer que las distintas variables se distribuyen de manera Normal:\n",
    "\n",
    "$$p(x_i) = \\prod_{j=1}^k \\frac{1}{\\sqrt{2\\pi}\\sigma_j}*\\exp(-\\frac{(x_{i,j}-\\mu_j)}{2\\sigma_j^2}),$$\n",
    "\n",
    "con \n",
    "\n",
    "$$\\mu_j = \\frac{1}{N}\\sum_{i=1}^N x_{i,j}, ~~~~ \\sigma^2_j = \\frac{1}{N} \\sum_{i=1}^N (x_{i,j}-\\mu_j)^2.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ecommerce_data.loc[:, ['Time on Website', 'Yearly Amount Spent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_data['Time on Website'], test_data['Yearly Amount Spent']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['prob'] = ((1/((2*np.pi)**(1/2)*test_data['Time on Website'].std()))*np.exp(-(test_data['Time on Website']-test_data['Time on Website'].mean())**2/(2*test_data['Time on Website'].var()))*\n",
    "                     (1/((2*np.pi)**(1/2)*test_data['Yearly Amount Spent'].std()))*np.exp(-(test_data['Yearly Amount Spent']-test_data['Yearly Amount Spent'].mean())**2/(2*test_data['Yearly Amount Spent'].var())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_rareza = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora usando _sklearn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(covariance_type='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = ecommerce_data.loc[:, ['Time on Website', 'Yearly Amount Spent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_rareza = 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se puden eliminar algunos supuestos:\n",
    "\n",
    "- Otras distribuciones de probabilidad.\n",
    "- No independencia de las variables.\n",
    "\n",
    "#### O usar otras metodologías:\n",
    "\n",
    "- Isolation Forest.\n",
    "- One Class SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
