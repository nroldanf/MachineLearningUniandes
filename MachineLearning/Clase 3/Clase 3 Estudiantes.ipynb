{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad de Los Andes - Facultad de Economía** <br>\n",
    "**Machine Learning para Business Intelligence** <br>\n",
    "**_Paula Rodríguez, Juan S. Moreno, Mateo Dulce_**\n",
    "# Clase 3: Modelos de Regresión\n",
    "\n",
    "En esta clase se cubriran los modelos estándar de regresión:\n",
    "\n",
    "- Mínimos cuadrados ordinarios (Regresión Lineal)\n",
    "- Regresión polinomial\n",
    "- Regresión Logística\n",
    "- Linear Discriminant Analysis\n",
    "- Regularización L1 y L2\n",
    "- Árboles de regresión\n",
    "\n",
    "Además, para evaluar el desempeño de los modelos implementados, se estudiarán las métricas de evaluación:\n",
    "- R-cuadrado\n",
    "- MSE\n",
    "- MAPE\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/RodrigoLaraMolina/DPATTSrc/master/ML2.png\" alt=\"ML\" style=\"width: 500px;\" align=\"center\" frameborder=\"200\"/>\n",
    "\n",
    "_(Imagen tomada de [Medium - Different types of Machine learning and their types.](https://medium.com/deep-math-machine-learning-ai/different-types-of-machine-learning-and-their-types-34760b9128a2))_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introducción a Scikit-Learn\n",
    "\n",
    "Existen varias librerias de Python que proveen implementaciones solidas de multiples algoritmos de aprendizaje de máquinas. Una de las más conocidas es [Scikit-Learn](http://scikit-learn.org). Scikit-Learn se caracteriza por ser una API limpia, uniforme y optimizada, y por tener una documentación en línea muy útil y completa.Una ventaja de esta uniformidad es que una vez que comprende el uso básico y la sintaxis de Scikit-Learn para un tipo de modelo, cambiar a un nuevo modelo o algoritmo es muy sencillo.\n",
    "\n",
    "### Uso básico de la API\n",
    "\n",
    "Por lo general, los pasos a seguir para utilizar los modelos implementados en Scikit-Learn son:\n",
    "\n",
    "1. Seleccionar una clase de modelo importando la clase de estimador apropiada de Scikit-Learn.\n",
    "2. Seleccionar los hiper parámetros del modelo al instanciar la clase anterior con estos valores.\n",
    "3. Organizar los datos en una matriz de variables y un vector objetivo.\n",
    "4. Ajustar el modelo a los datos llamando al método `` fit () `` de la instancia del modelo.\n",
    "5. Evaluar el modelo en nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mínimos Cuadrados Ordinarios\n",
    "### Regresión lineal univariada\n",
    "\n",
    "Los modelos de regresión lineal son un buen punto de partida para las tareas de regresión. Dichos modelos son populares porque pueden ajustarse muy rápidamente y son muy interpretables.\n",
    "\n",
    "Comenzaremos con la regresión lineal más familiar, un ajuste en línea recta a los datos.\n",
    "Un ajuste en línea recta es un modelo de la forma\n",
    "$$\n",
    "y = ax + b\n",
    "$$\n",
    "donde $a$ es la *pendiente*, y $b$ is el *intercepto*.\n",
    "\n",
    "Considere los siguientes datos, que están dispersos alrededor de un modelo lineal con una pendiente de 2 y una intersección de -5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar paquetes estandar\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar datos sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para tener replicabilidad\n",
    "\n",
    "\n",
    "# generamos puntos distribuidos de manera uniforme entre 0 y 10\n",
    "\n",
    "\n",
    "# generamos los valores de y usando un modelo lineal con pendiente 2\n",
    "# e intercepto -5 mas un ruido alatorio\n",
    "\n",
    "\n",
    "# construit un grafico de puntos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrar el mejor ajuste (usando Numpy)\n",
    "\n",
    "Escribiendo el modelo de forma matricial tenemos: $Y = X^T \\beta$.\n",
    "\n",
    "Queremos encontrar $\\hat \\beta$ que minimice el costo $(Y-\\hat Y)^2$ donde $\\hat Y = X^T \\hat \\beta$. <br>\n",
    "Esto es $\\hat \\beta = (X^TX)^{-1}X^TY$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolvamos el problema utilziando el paquete numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la matriz que contiene una columna de 1's y la variable x\n",
    "\n",
    "\n",
    "# np.matrix toma cada entrada como una fila.\n",
    "# trasponemos para tener observaciones x variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimación de beta\n",
    "\n",
    "print(\"Pendiente del modelo: {}\".format())\n",
    "print(\"Intercepto del modelo: {}\".format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrar el mejor ajuste utilizando Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar LinearRegression de Scikit-Learn\n",
    "\n",
    "\n",
    "# crear un modelo lineal con intercepto\n",
    "\n",
    "\n",
    "# ajustar el modelo a los datos\n",
    "\n",
    "\n",
    "# graficar la funcion lineal estimada\n",
    "\n",
    "\n",
    "# build plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pendiente del modelo:    \", )\n",
    "print(\"Intercepto del modelo:\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de desempeño\n",
    "\n",
    "- $MSE = mean((Y-\\hat Y)^2)$ \n",
    "<br>\n",
    "<br>\n",
    "- $MAPE = mean(\\mid Y-\\hat Y \\mid)$ \n",
    "<br>\n",
    "<br>\n",
    "- $R^2 = \\dfrac{\\sigma^{2}_{XY}}{\\sigma^{2}_{X}\\sigma^{2}_{Y}}$ donde $\\sigma^{2}_{XY}$ es la covarianza de $X,Y$, $\\sigma^{2}_{X}$ la varianza de $X$ y $\\sigma^{2}_{Y}$ la varianza de $Y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar la predicción dentro de muestra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error cuadrático medio en el entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error cuadrático medio en el entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error cuadrático medio en el entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen otros paquetes que contienen implementaciones de este mismo modelo. Por ejemplo pueden pribar con: <br>\n",
    "``statsmodels.formula.api.ols``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal Múltiple\n",
    "\n",
    "El estimador ``LinearRegression`` también puede estimar modelos multivariables de la forma\n",
    "$$\n",
    "y = a_0 + a_1 x_1 + a_2 x_2 + \\cdots\n",
    "$$\n",
    "donde hay multiples valores para $x$.\n",
    "Geométricamente, esto es ajustar un plano a puntos en tres dimenciones o un hiper plano para dimensiones mayores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos datos con 5 variables distribuidas uniformemente entre 0 y 10\n",
    "# creamos la variable dependiente y como un modelo lineal de x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(211,projection='3d')\n",
    "\n",
    "ax.scatter(X.T[0],X.T[1], c='r', marker='o')\n",
    "\n",
    "# generar una grilla de x,y\n",
    "xx, yy = np.meshgrid(X.T[0],X.T[1])\n",
    "\n",
    "exog = pd.core.frame.DataFrame({'X': xx.ravel(), 'Y': yy.ravel()})\n",
    "out = model.predict(exog)\n",
    "ax.plot_surface(xx, yy,\n",
    "                out.reshape(xx.shape),\n",
    "                rstride=1,\n",
    "                cstride=1,\n",
    "                color='None',\n",
    "                alpha = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regresión polinomial\n",
    "\n",
    "Una manera de adaptar la regresión lineal a una relación no lineal entre las variabels es transformar los datos de acuerda a *funciones base*.\n",
    "La idea es tomar el modelo lineal multivariable:\n",
    "$$\n",
    "y = a_0 + a_1 x_1 + a_2 x_2 + a_3 x_3 + \\cdots\n",
    "$$\n",
    "y construir $x_1, x_2, x_3,$ del input unidimensional $x$.\n",
    "Tenemos entonces $x_n = f_n(x)$, donde $f_n()$ es una función que transforma nuestros datos.\n",
    "\n",
    "Por ejemplo, si $f_n(x) = x^n$, nuestro modelo se convierte en una regresión polinomial:\n",
    "$$\n",
    "y = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots\n",
    "$$\n",
    "Note que este modelo sigue siendo un *modelo lineal*. La linearidad se refiere al hecho de que los coeficientes $a_n$ son lineales entre ellos. Lo que hemos hecho es tomar la variable unidimensional $x$ y proyectarla en dimensiones mayores para que así el ajuste lineal pueda ajustar relaciones más complejas entre $x$ y $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de scikit learn que crea tranforma los datos\n",
    "\n",
    "# crear datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La manera más 'limpia' de realizar *feature engineering* en los modelos de ML es utilizando un pipeline. Creamos ahora un modelo polinomial de grado 7 usando ``make_pipeline`` y ``LinearRegression`` de Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el modelo polinomial de grado 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replicabilidad\n",
    "# creacion de x aleatorio entre 0 y 10\n",
    "# creacion de y como respuesta no lineal de x\n",
    "\n",
    "#ajuste del modelo polinomial\n",
    "#prediccion de y\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# graficar valores reales de y vs prediccion\n",
    "y_pred = poly_model.predict(x[:, np.newaxis])\n",
    "plt.scatter(y,y_pred)\n",
    "plt.xlabel(\"Real: $Y_i$\")\n",
    "plt.ylabel(\"Predicted: $\\hat{Y}_i$\")\n",
    "plt.title(\"Real vs Predicted: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "plt.plot([-1,1.2],[-1,1.2],color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de grado con validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta y la siguiente sección estudiaremos el **Conjunto de datos de vivienda de Boston** que consiste en el precio de las casas en varios lugares de Boston. Junto con el precio, el conjunto de datos también proporciona información como la tasa de criminalidad (CRIM), áreas de negocios no minoristas en la ciudad (INDUS), la edad de las personas que poseen la casa (EDAD) y hay muchos otros atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2.1. Boston house prices dataset\n",
    "\n",
    "# display an Inline Frame\n",
    "from IPython.display import IFrame \n",
    "IFrame('https://scikit-learn.org/stable/datasets/index.html#boston-dataset',\n",
    "       width=750, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the Boston data set in it's original format (dictionary)\n",
    "from sklearn.datasets import load_boston\n",
    "raw_data = load_boston()\n",
    "\n",
    "# Create a Pandas Data Frame with the Boston data\n",
    "boston = pd.DataFrame(raw_data.data)\n",
    "boston.columns = raw_data.feature_names\n",
    "boston['PRICE'] = raw_data.target\n",
    "display(boston.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos una función para el pipeline de la regresion polinomial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos datos univariados del dataset de boston\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar paquetes para graficar\n",
    "%matplotlib inline\n",
    "import seaborn; seaborn.set()  # plot formatting\n",
    "\n",
    "#definir x test\n",
    "\n",
    "#graficar para varios grados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar validation_curve\n",
    "\n",
    "\n",
    "#graficar\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación con GridSearchCV\n",
    "\n",
    "<img src=\"img/fold-CV.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar GridSearchCV\n",
    "\n",
    "#definir grilla de parametros\n",
    "\n",
    "# realizar grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el GridSearchCV a los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirar cuales son los mejores parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficar el mejor modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regularización Ridge y Lasso\n",
    "\n",
    "La regresión de Ridge y Lasso son técnicas generalmente utilizadas para crear modelos que generealicen bien al tener una gran cantidad de variables. Aquí \"grande\" puede significar cualquiera de dos cosas:\n",
    "\n",
    "- Lo suficientemente grande como para mejorar la tendencia de un modelo a sobreajustar\n",
    "- Lo suficientemente grande como para causar desafíos computacionales\n",
    "\n",
    "Modelos de Regularización:\n",
    "\n",
    "1. **Ridge:** Realiza la regularización L2, es decir, agrega una penalización equivalente al cuadrado de la magnitud de los coeficientes\n",
    "2. **Lasso:** Realiza la regularización L1, es decir, agrega una penalización equivalente al valor absoluto de la magnitud de los coeficientes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear datos\n",
    "\n",
    "\n",
    "# graficar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar en train y test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class GaussianFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Uniformly spaced Gaussian features for one-dimensional input\"\"\"\n",
    "    \n",
    "    def __init__(self, N, width_factor=2.0):\n",
    "        self.N = N\n",
    "        self.width_factor = width_factor\n",
    "    \n",
    "    @staticmethod\n",
    "    def _gauss_basis(x, y, width, axis=None):\n",
    "        arg = (x - y) / width\n",
    "        return np.exp(-0.5 * np.sum(arg ** 2, axis))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # create N centers spread along the data range\n",
    "        self.centers_ = np.linspace(X.min(), X.max(), self.N)\n",
    "        self.width_ = self.width_factor * (self.centers_[1] - self.centers_[0])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self._gauss_basis(X[:, :, np.newaxis], self.centers_,\n",
    "                                 self.width_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear pipeline y ajustar modelo a los datos\n",
    "\n",
    "\n",
    "\n",
    "# graficar el modelo ajustado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular MSE\n",
    "mse_train = \n",
    "mse_test = \n",
    "print(\"El MSE en entrenamiento del modelo Rodge es: {0:.3f}\".format(mse_train))\n",
    "print(\"El MSE en prueba del modelo Rodge es: {0:.3f}\".format(mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rregresión Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar Ridge\n",
    "\n",
    "# definir modelo y ajustar a los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar el modelo realizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular MSE\n",
    "\n",
    "mse_train = \n",
    "mse_test = \n",
    "print(\"El MSE en entrenamiento del modelo Ridge es: {0:.3f}\".format(mse_train))\n",
    "print(\"El MSE en prueba del modelo Ridge es: {0:.3f}\".format(mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar Lasso\n",
    "\n",
    "# definir y ajustar modelo Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar el modelo realizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular MSE\n",
    "\n",
    "mse_train = \n",
    "mse_test = \n",
    "print(\"El MSE en entrenamiento del modelo Lasso es: {0:.3f}\".format(mse_train))\n",
    "print(\"El MSE en prueba del modelo Lasso es: {0:.3f}\".format(mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Discriminant Analysis\n",
    "\n",
    "El _Linear Discriminant Analysis (LDA)_ es una técnica supervisada de reducción de dimensionalidad. El objetivo es proyectar un conjunto de datos en un espacio de dimensiones inferiores con buena capacidad de separación de clases para evitar el sobreajuste y también reducir los costos computacionales.\n",
    "\n",
    "<img src=\"img/lda1.png\" width=\"250\" class=\"center\"><img src=\"img/lda2.png\" width=\"250\" class=\"center\"><img src=\"img/lda3.png\" width=\"250\" class=\"center\"><img src=\"img/lda4.png\" width=\"250\" class=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo datos\n",
    " #importar LDA de scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar datos y separar X y Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustar modelo LDA\n",
    "\n",
    "#graficar datos con LD1 y LD2\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.scatter(\n",
    "    X_lda[:,0],\n",
    "    X_lda[:,1],\n",
    "    c=pd.factorize(y)[0] + 1,\n",
    "    alpha=0.7,\n",
    "    edgecolors='b'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Árboles de regresión\n",
    "\n",
    "Cubriremos los siguientes temas:\n",
    "- Selección de hiper-parámetros.\n",
    "- Interpretación de los árboles.\n",
    "- Importancia de variables.\n",
    "- Tipos de ensambles: simulatáneos y secuenciales.\n",
    "- Regularización de árboles.\n",
    "- Evaluación de los modelos.\n",
    "\n",
    "Estudiaremos los siguientes tres modelos:\n",
    "- Árboles de regresión\n",
    "- Random Forest (Bosques aleatorios)\n",
    "- Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de regresión\n",
    "\n",
    "Los árboles de decisión son formas extremadamente intuitivas para clasificar o etiquetar objetos: simplemente hace una serie de preguntas diseñadas para concentrarse en la regresión o clasificación.\n",
    "Por ejemplo, si desea construir un árbol de decisión para clasificar una casa, puede construir el que se muestra aquí:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/RodrigoLaraMolina/DPATTSrc/master/decision-tree-house.png\" alt=\"decision_tree\" style=\"width: 700px;\" align=\"center\" frameborder=\"200\"/>\n",
    "\n",
    "<img src=\"img/regression_trees.png\" width=\"800\" class=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tree from Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos las variables independientes y dependiente\n",
    "\n",
    "# importar función para separar dataset en entrenamiento y prueba\n",
    "\n",
    "\n",
    "# Separamos dataset con test del 30% de las observaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el arbol de decisión\n",
    "\n",
    "\n",
    "# ajustar el modelo a los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización del árbol"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# importar los paquetes para visualizar arboles de decision\n",
    "from graphviz import Source\n",
    "from IPython.display import Image\n",
    "\n",
    "# crear la visualizacion como png\n",
    "graph = Source(tree.export_graphviz(tree_model, out_file=None,\n",
    "                                     feature_names=X.columns))\n",
    "png_bytes = graph.pipe(format='png')\n",
    "with open('dtree_pipe.png','wb') as f:\n",
    "    f.write(png_bytes)\n",
    "\n",
    "# mostrar la imagen creada   \n",
    "from IPython.display import Image\n",
    "print('Double click to zoom')\n",
    "Image(png_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error de entranamiento y prueba\n",
    "pred_train = \n",
    "pred_test= \n",
    "mse_train = \n",
    "mse_test = \n",
    "print(\"El mse de entrenamiento es: {0:.3f}\".format(mse_train))\n",
    "print(\"El mse de prueba es: {0:.3f}\".format(mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__HAY OVERFITTING!!!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularización de árboles (_podar el árbol_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir grilla de parametros\n",
    "\n",
    "#realizar grid search cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar mejor modelo\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# crear la visualizacion como png\n",
    "graph = Source(tree.export_graphviz(best_tree, out_file=None,\n",
    "                                     feature_names=X.columns))\n",
    "png_bytes = graph.pipe(format='png')\n",
    "with open('best_tree.png','wb') as f:\n",
    "    f.write(png_bytes)\n",
    "\n",
    "# mostrar la imagen creada   \n",
    "from IPython.display import Image\n",
    "print('Double click to zoom')\n",
    "Image(png_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error de entranamiento y prueba\n",
    "pred_train = \n",
    "pred_test= \n",
    "mse_train = \n",
    "mse_test = \n",
    "print(\"El mse de entrenamiento para el mejor árbol es: {0:.3f}\".format(mse_train))\n",
    "print(\"El mse de prueba para el mejor árbol es: {0:.3f}\".format(mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe con las importancias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest y Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la función para estimar RandomForest\n",
    "# Importo la función para estimar el boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino el RandomForest\n",
    "\n",
    "\n",
    "# ajusto el modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino el GBM\n",
    "\n",
    "# ajusto el modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error de entranamiento y prueba\n",
    "pred_train_rf = \n",
    "pred_test_rf= \n",
    "\n",
    "pred_train_gbm = \n",
    "pred_test_gbm= \n",
    "\n",
    "\n",
    "print(\"El mse de entrenamiento para el RF es: {0:.3f}\".format(mean_squared_error(Y_train,pred_train_rf)))\n",
    "print(\"El mse de prueba para el RF es: {0:.3f}\".format(mean_squared_error(Y_test,pred_test_rf)))\n",
    "print(\" \")\n",
    "print(\"El mse de entrenamiento para el GBM es: {0:.3f}\".format(mean_squared_error(Y_train,pred_train_gbm)))\n",
    "print(\"El mse de prueba para el GBM es: {0:.3f}\".format(mean_squared_error(Y_test,pred_test_gbm)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Ejercicio para la casa:** Utilice ``GridSearchCV`` para seleccionar los parámetros que mejor ajusten los modelos de Random Forest y Gradient Boosting._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen Rápido: Qué hemos hecho hasta ahora?\n",
    "_Imagen tomada de [Dataconomy: INFOGRAPHIC: A BEGINNER’S GUIDE TO MACHINE LEARNING ALGORITHMS](https://dataconomy.com/2017/03/beginners-guide-machine-learning/)_\n",
    "\n",
    "<img src=\"img/resumen.png\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
